# This file is part of JSC's public easybuild repository (https://github.com/easybuilders/jsc)
# on juwels booster, one needs to call "export UCX_LOG_LEVEL=FATAL ebw ...

easyblock = 'PythonBundle'

name = 'Horovod'
version = '0.20.3'
local_tf_version = '2.3.1'
versionsuffix = '-Python-%(pyver)s'

homepage = 'https://github.com/uber/horovod'
description = "Horovod is a distributed training framework for TensorFlow and PyTorch."

toolchain = {'name': 'gomkl', 'version': '2020'}
toolchainopts = {'usempi': True, 'pic': True}


builddependencies = [
    ('CMake', '3.18.0'),
]
dependencies = [
    ('Python', '3.8.5'),
    ('TensorFlow', local_tf_version, '-Python-%(pyver)s', ('gcccoremkl', '9.3.0-2020.2.254')),
    ('UCX', '1.9.0', '', SYSTEM),  # Forced because default was 1.8.1. If the default is 1.9.0, this can go away
    ('PyTorch', '1.7.0', '-Python-%(pyver)s', ('gcccoremkl', '9.3.0-2020.2.254')),
    ('NCCL', '2.8.3-1', '-CUDA-11.0'),
]

use_pip = True
sanity_pip_check = True

# possible vars:
# HOROVOD_BUILD_ARCH_FLAGS - additional C++ compilation flags to pass in for your build architecture.
# HOROVOD_CUDA_HOME - path where CUDA include and lib directories can be found.
# HOROVOD_BUILD_CUDA_CC_LIST - List of compute capabilities to build Horovod CUDA
# kernels for (example: HOROVOD_BUILD_CUDA_CC_LIST=60,70,75)
# HOROVOD_ROCM_HOME - path where ROCm include and lib directories can be found.
# HOROVOD_NCCL_HOME - path where NCCL include and lib directories can be found.
# HOROVOD_NCCL_INCLUDE - path to NCCL include directory.
# HOROVOD_NCCL_LIB - path to NCCL lib directory.
# HOROVOD_NCCL_LINK - {SHARED, STATIC}. Mode to link NCCL library. Defaults to STATIC for CUDA, SHARED for ROCm.
# HOROVOD_WITH_GLOO - {1}. Require that Horovod is built with Gloo support enabled.
# HOROVOD_WITHOUT_GLOO - {1}. Skip building with Gloo support.
# HOROVOD_WITH_MPI - {1}. Require that Horovod is built with MPI support enabled.
# HOROVOD_WITHOUT_MPI - {1}. Skip building with MPI support.
# HOROVOD_GPU - {CUDA, ROCM}. Framework to use for GPU operations.
# HOROVOD_GPU_OPERATIONS - {NCCL, MPI}. Framework to use for GPU tensor allreduce, allgather, and broadcast.
# HOROVOD_GPU_ALLREDUCE - {NCCL, MPI}. Framework to use for GPU tensor allreduce.
# HOROVOD_GPU_ALLGATHER - {NCCL, MPI}. Framework to use for GPU tensor allgather.
# HOROVOD_GPU_BROADCAST - {NCCL, MPI}. Framework to use for GPU tensor broadcast.
# HOROVOD_ALLOW_MIXED_GPU_IMPL - {1}. Allow Horovod to install with NCCL allreduce and MPI GPU allgather /
# broadcast. Not recommended due to a possible deadlock.
# HOROVOD_CPU_OPERATIONS - {MPI, GLOO, CCL}. Framework to use for CPU tensor allreduce, allgather, and broadcast.
# HOROVOD_CMAKE - path to the CMake binary used to build Gloo (not required when using MPI).
# HOROVOD_WITH_TENSORFLOW - {1}. Require Horovod to install with TensorFlow support enabled.
# HOROVOD_WITHOUT_TENSORFLOW - {1}. Skip installing TensorFlow support.
# HOROVOD_WITH_PYTORCH - {1}. Require Horovod to install with PyTorch support enabled.
# HOROVOD_WITHOUT_PYTORCH - {1}. Skip installing PyTorch support.
# HOROVOD_WITH_MXNET - {1}. Require Horovod to install with MXNet support enabled.
# HOROVOD_WITHOUT_MXNET - {1}. Skip installing MXNet support.

# prebuildopts = 'export LDSHARED="$CC -shared" && '
# prebuildopts += ' HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITHOUT_PYTORCH=1 HOROVOD_WITHOUT_MXNET=1 '
# prebuildopts += ' HOROVOD_NCCL_LINK=SHARED HOROVOD_NCCL_HOME=$EBROOTNCCL '
# prebuildopts += ' HOROVOD_GPU_OPERATIONS=NCCL '
# prebuildopts += ' HOROVOD_CPU_OPERATIONS=MPI '
# prebuildopts += ' HOROVOD_GPU_ALLREDUCE=NCCL '
# prebuildopts += ' HOROVOD_GPU_BROADCAST=NCCL '
# prebuildopts += ' HOROVOD_WITH_MPI=1 '


prebuildopts = 'export LDSHARED="$CC -shared" && '
prebuildopts += ' HOROVOD_NCCL_LINK=SHARED HOROVOD_GPU_ALLREDUCE=NCCL HOROVOD_NCCL_HOME=$EBROOTNCCL '
prebuildopts += ' HOROVOD_WITH_TENSORFLOW=1 HOROVOD_WITH_PYTORCH=1'
prebuildopts += ' NVCC_GENCODE="-gencode=arch=compute_70,code=sm_70 \
                                -gencode=arch=compute_75,code=sm_75 \
                                -gencode=arch=compute_80,code=sm_80"'

preinstallopts = prebuildopts


exts_default_options = {'source_urls': [PYPI_SOURCE]}

exts_list = [
    ('horovod', version, {
        'checksums': ['6ebc90d627af486d44335ed48489e1e8dc190607574758867c52e4e17d75a247'],
        'cuda_compute_capabilities': ['7.0', '7.5', '8.0'],
    }),
]

sanity_check_paths = {
    'files': ['bin/horovodrun'],
    'dirs': ['lib/python%(pyshortver)s/site-packages'],
}

# This makes openmpi work. It's up to the sysadmins to correct me here.
modextravars = {'HOROVOD_MPI_THREADS_DISABLE': '1'}

modloadmsg = 'Setting HOROVOD_MPI_THREADS_DISABLE=1. '

moduleclass = 'tools'
